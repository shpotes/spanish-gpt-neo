{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "d7279c289e64d58abd95577c6ee50dae7bd0503a06b456ac21124395f1fe24b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/shpotes/gpt2\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\nCould not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-035424.282099': Permission denied\nCould not open any log file.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset, load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import json\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import transformers\n",
    "from flax import jax_utils, traverse_util\n",
    "from flax.jax_utils import unreplicate\n",
    "from flax.training import train_state\n",
    "from flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\n",
    "from flax.serialization import to_bytes, from_bytes\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    GPTNeoForCausalLM,\n",
    "    FlaxAutoModelForCausalLM,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    is_tensorboard_available,\n",
    ")\n",
    "from transformers.testing_utils import CaptureLogger\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from src.config import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    dropout_rng: jnp.ndarray\n",
    "\n",
    "    def replicate(self):\n",
    "        return jax_utils.replicate(self).replace(dropout_rng=shard_prng_key(self.dropout_rng))\n",
    "\n",
    "\n",
    "def data_loader(rng: jax.random.PRNGKey, dataset: Dataset, batch_size: int, shuffle: bool = False):\n",
    "    \"\"\"\n",
    "    Returns batches of size `batch_size` from truncated `dataset`, sharded over all local devices.\n",
    "    Shuffle batches if `shuffle` is `True`.\n",
    "    \"\"\"\n",
    "    steps_per_epoch = len(dataset) // batch_size\n",
    "\n",
    "    if shuffle:\n",
    "        batch_idx = jax.random.permutation(rng, len(dataset))\n",
    "    else:\n",
    "        batch_idx = jnp.arange(len(dataset))\n",
    "\n",
    "    batch_idx = batch_idx[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
    "    batch_idx = batch_idx.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    for idx in batch_idx:\n",
    "        batch = dataset[idx]\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "\n",
    "        batch = shard(batch)\n",
    "\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def write_train_metric(summary_writer, train_metrics, train_time, step):\n",
    "    summary_writer.scalar(\"train_time\", train_time, step)\n",
    "\n",
    "    train_metrics = get_metrics(train_metrics)\n",
    "    for key, vals in train_metrics.items():\n",
    "        tag = f\"train_{key}\"\n",
    "        for i, val in enumerate(vals):\n",
    "            summary_writer.scalar(tag, val, step - len(vals) + i + 1)\n",
    "\n",
    "\n",
    "def write_eval_metric(summary_writer, eval_metrics, step):\n",
    "    for metric_name, value in eval_metrics.items():\n",
    "        summary_writer.scalar(f\"eval_{metric_name}\", value, step)\n",
    "\n",
    "\n",
    "def create_learning_rate_fn(\n",
    "    train_ds_size: int, train_batch_size: int, num_train_epochs: int, num_warmup_steps: int, learning_rate: float\n",
    ") -> Callable[[int], jnp.array]:\n",
    "    \"\"\"Returns a linear warmup, linear_decay learning rate function.\"\"\"\n",
    "    steps_per_epoch = train_ds_size // train_batch_size\n",
    "    num_train_steps = steps_per_epoch * num_train_epochs\n",
    "    warmup_fn = optax.linear_schedule(init_value=0.0, end_value=learning_rate, transition_steps=num_warmup_steps)\n",
    "    decay_fn = optax.linear_schedule(\n",
    "        init_value=learning_rate, end_value=0, transition_steps=num_train_steps - num_warmup_steps\n",
    "    )\n",
    "    schedule_fn = optax.join_schedules(schedules=[warmup_fn, decay_fn], boundaries=[num_warmup_steps])\n",
    "    return schedule_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArguments(\n",
    "    model_name_or_path=\"EleutherAI/gpt-neo-125M\",\n",
    "    tokenizer_name=\"flax-community/bertin-roberta-large-spanish\",\n",
    "    dtype=\"bfloat16\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args = DataTrainingArguments(\n",
    "    dataset_name=\"oscar\", \n",
    "    dataset_config_name=\"unshuffled_deduplicated_es\", \n",
    "    block_size=1024,\n",
    "    max_train_samples=10000, \n",
    "    max_eval_samples=1000, \n",
    "    preprocessing_num_workers=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=1,\n",
    "    output_dir=\"model/\", \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16, \n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.1,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    warmup_steps=100,\n",
    "    push_to_hub=False,\n",
    "    overwrite_output_dir=True,\n",
    "    report_to=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\n",
    "    data_args.dataset_name,\n",
    "    data_args.dataset_config_name, \n",
    "    streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_dataset = load_dataset(\n",
    "#    'large_spanish_corpus',\n",
    "#    name='ParaCrawl',\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name, cache_dir=model_args.cache_dir, use_fast=model_args.use_fast_tokenizer\n",
    ")\n",
    "config.vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of FlaxGPTNeoForCausalLM were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized because the shapes did not match:\n- ('transformer', 'wte', 'embedding'): found shape (50257, 768) in the checkpoint and (50265, 768) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = FlaxAutoModelForCausalLM.from_pretrained(\n",
    "    model_args.model_name_or_path, config=config, seed=training_args.seed, dtype=getattr(jnp, model_args.dtype), ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    output = tokenizer(examples[\"text\"])\n",
    "    \n",
    "    return output\n",
    "\n",
    "tokenized_dataset = train_dataset[\"train\"].map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbatch = next(iter(tokenized_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_args.block_size is None:\n",
    "    block_size = tokenizer.model_max_length\n",
    "    if block_size > config.max_position_embeddings:\n",
    "        logger.warning(\n",
    "            f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}). \"\n",
    "            \"Picking 1024 instead. You can change that default value by passing --block_size xxx.\"\n",
    "        )\n",
    "        block_size = 1024\n",
    "else:\n",
    "    if data_args.block_size > tokenizer.model_max_length:\n",
    "        logger.warning(\n",
    "            f\"The block_size passed ({data_args.block_size}) is larger than the maximum length for the model\"\n",
    "            f\"({tokenizer.model_max_length}). Using block_size={tokenizer.model_max_length}.\"\n",
    "        )\n",
    "    block_size = min(data_args.block_size, tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(training_args.seed)\n",
    "rng, dropout_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = int(training_args.per_device_train_batch_size) * jax.device_count() * training_args.gradient_accumulation_steps\n",
    "eval_batch_size = int(training_args.per_device_eval_batch_size) * jax.device_count()\n",
    "total_train_steps = training_args.max_steps * training_args.gradient_accumulation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:absl:A polynomial schedule was set with a non-positive `transition_steps` value; this results in a constant schedule with value `init_value`.\n"
     ]
    }
   ],
   "source": [
    "linear_decay_lr_schedule_fn = create_learning_rate_fn(\n",
    "    len(train_dataset),\n",
    "    train_batch_size,\n",
    "    training_args.num_train_epochs,\n",
    "    training_args.warmup_steps,\n",
    "    training_args.learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_args.adafactor:\n",
    "    # We use the default parameters here to initialize adafactor,\n",
    "    # For more details about the parameters please check https://github.com/deepmind/optax/blob/ed02befef9bf81cbbf236be3d2b0e032e9ed4a40/optax/_src/alias.py#L74\n",
    "    optimizer = optax.adafactor(\n",
    "        learning_rate=linear_decay_lr_schedule_fn,\n",
    "    )\n",
    "else:\n",
    "    optimizer = optax.adamw(\n",
    "        learning_rate=linear_decay_lr_schedule_fn,\n",
    "        b1=training_args.adam_beta1,\n",
    "        b2=training_args.adam_beta2,\n",
    "        eps=training_args.adam_epsilon,\n",
    "        weight_decay=training_args.weight_decay,\n",
    "    )\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1),\n",
    "        optimizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'embedding': DeviceArray([[-0.0175781, 0.0108032, -0.0317383, ..., -0.0303955,\n",
       "               0.0211182, 0.0090332],\n",
       "              [-0.0317383, 0.0285645, 0.0112305, ..., -0.0390625,\n",
       "               -0.0390625, 0.0224609],\n",
       "              [0.012207, 0.0196533, -0.0317383, ..., 0.0108032, 0.0098877,\n",
       "               -0.0105591],\n",
       "              ...,\n",
       "              [0.0310059, 0.00285339, 0.00167084, ..., 0.0146484,\n",
       "               0.00817871, -0.0100708],\n",
       "              [-0.0214844, 0.0179443, -0.0332031, ..., 0.00689697,\n",
       "               -0.0228271, 0.0090332],\n",
       "              [-0.0159912, 0.0098877, 0.00167084, ..., 0.0112305,\n",
       "               -0.0153809, 0.00405884]], dtype=bfloat16)}"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "model.params['transformer']['wte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = {'transformer': {'wte': model.params['transformer']['wte']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n",
      "Could not open the log file '/tmp/tpu_logs/tpu_driver.t1v-n-c632aea2-w-0.shpotes.log.INFO.20210714-042834.282099': Permission denied\n",
      "Could not open any log file.\n"
     ]
    }
   ],
   "source": [
    "state = TrainState.create(\n",
    "    apply_fn=model.__call__, \n",
    "    params=trainable_params, \n",
    "    tx=optimizer,\n",
    "    dropout_rng=dropout_rng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits, labels):\n",
    "    shift_logits = logits[..., :-1, :]\n",
    "    shift_labels = labels[..., 1:]\n",
    "    loss = optax.softmax_cross_entropy(shift_logits, onehot(shift_labels, shift_logits.shape[-1]))\n",
    "    return loss.mean()                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rng, new_dropout_rng = jax.random.split(state.dropout_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(params):\n",
    "    labels = batch.pop(\"labels\")\n",
    "    logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "    loss = loss_fn(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_282099/4032740256.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_282099/4193312384.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "compute_loss(trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}